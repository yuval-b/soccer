{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soccer Networks\n",
    "\n",
    "**Yuval Berman**\n",
    "\n",
    "Making passing networks out of the events logs stream and evaluating metrics for temporal windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.cm as mplcm\n",
    "import matplotlib.colors as colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import up sound alert dependencies\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "def allDone():\n",
    "    display(Audio(url='https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav', autoplay=True))\n",
    "## Insert whatever audio file you want above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate to the relevant directory\n",
    "os.chdir('/Users/Yuval/Desktop/Pawsey/data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the players (not necessary for global entropy, but helps if wanting to find individual node\n",
    "# entropy or visualise the passing network)\n",
    "players = pd.read_json('players.json')\n",
    "players = players.rename(columns ={'wyId': 'playerId'}) # rename for convenience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_events = os.listdir('cleaned_events/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_df_processing(name):\n",
    "    \n",
    "    df = pd.read_json('cleaned_events/'+name)\n",
    "    \n",
    "    # Merge the two databases together\n",
    "    df = df.merge(players, how = 'left', on = 'playerId')\n",
    "    \n",
    "    # Let's clean it up a bit and get rid of some unnecessary info so we have just what we need\n",
    "    df.drop(['passportArea', 'weight', 'firstName','middleName','lastName','currentTeamId',\n",
    "         'birthDate','height','role','foot','currentNationalTeamId','birthArea','subEventId',\n",
    "         'id','xStart', 'xEnd', 'yStart', 'yEnd', 'attackMetres'],inplace = True, axis = 1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_game(df, matchId):\n",
    "    # Finds the match we're after.\n",
    "    df = df.loc[df['matchId'] == matchId]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuous_time(df):\n",
    "    # Converts to a continuous 90 min (ie 90*60 = 5400 second) game\n",
    "    firsthalf = df.loc[df['matchPeriod'] == '1H']\n",
    "    first_half_length = list(firsthalf['eventSec'])[-1]\n",
    "    df.loc[ df.matchPeriod == '2H' , 'eventSec'] += first_half_length\n",
    "    \n",
    "    #Take out extra time / penalties for the cup games\n",
    "    df = df.loc[df['matchPeriod'] != 'E1']\n",
    "    df = df.loc[df['matchPeriod'] != 'E2']\n",
    "    df = df.loc[df['matchPeriod'] != 'P']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_handling(df):\n",
    "    # Cleans things up based on our interpretation of the events and how they relate to passes. Note the meaning of\n",
    "    # the events:\n",
    "    # 1 - duels (this is a hard one to define as it means many different things)\n",
    "    # 2 - fouls\n",
    "    # 3 - free kicks / corners (hence we add a node so that it picks these up as the first play in the chain)\n",
    "    # 4 - keeper leaving their line\n",
    "    # 7 - Touch, acceletation or clearance (also vague- get rid of touch/acc but keep clearance if its accurate)\n",
    "    # 8 - Pass - simple/smart, cross (main data we're after for this)\n",
    "    # 9 - Reflexes / save (however if tagged as inaccurate it means there was a goal)\n",
    "    # 10- Shot (add a shot node)\n",
    "    \n",
    "    df = df.loc[ df['eventId'] != 9]\n",
    "    df = df.loc[ df['eventId'] != 1]\n",
    "    df = df.loc[ df['eventId'] != 2]\n",
    "    df = df.loc[ df['eventId'] != 4]\n",
    "    df = df.loc[ df['eventId'] != 7]\n",
    "    df = df.loc[ df['subEventName'] != 'Touch']\n",
    "    df = df.loc[ df['subEventName'] != 'Acceleration']\n",
    "    df = df.loc[ (df['subEventName'] != 'Clearance') | (df['Result'] == 'Inaccurate')]\n",
    "    df = df.drop(df[(df.subEventName == 'Clearance') & (df.Result =='Inaccurate')].index)\n",
    "\n",
    "    # Create some new columns to see where passes ended up etc\n",
    "    df[\"next_event\"] = df['eventId'].shift(-1)\n",
    "    df[\"next_teamId\"] = df[\"teamId\"].shift(-1)\n",
    "    df[\"next_player\"] = df[\"playerId\"].shift(-1)\n",
    "    df.loc[ df[\"next_event\"] == 3, 'next_player'] = 0.5\n",
    "    df.loc[ df[\"eventId\"] == 10, 'next_player'] = 0\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def passeslist(df, teamIds):\n",
    "    \n",
    "    # Create a Passes column which only has successive events between the same team \n",
    "    df = df.drop( df[(df.teamId != df.next_teamId) & (df.next_player != 0)].index)\n",
    "    df['Passes'] = list(zip(df['playerId'], df['next_player']))\n",
    "    \n",
    "    # Get a passes list for each team\n",
    "    passes = []\n",
    "    for team in teamIds:    \n",
    "        temp = df.loc[df['teamId'] == team]\n",
    "        passes.append(list(temp['Passes']))\n",
    "\n",
    "    return passes[0], passes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_passes(passes):\n",
    "    # Builds a network for the team based on the passes as edges\n",
    "    n = nx.DiGraph()\n",
    "    for (i,j) in passes:\n",
    "        if n.has_edge(i,j):\n",
    "            n[i][j]['weight'] += 1\n",
    "        else:\n",
    "            n.add_edge(i,j, weight = 1)\n",
    "    \n",
    "    # Remove node 0.5 as only used to signify start of plays from free kicks / corners\n",
    "    if 0.5 in n.nodes():\n",
    "        n.remove_node(0.5)\n",
    "        \n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a function to calculate the entropy of each node from the transition matrix.\n",
    "def entropy(row):\n",
    "    enode = 0\n",
    "    for item in row:\n",
    "        if item > 0:\n",
    "            enode -= item * math.log10(item) # Entropy formula for each node.\n",
    "    return enode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entropy(net,playerlist):\n",
    "    # This function attempts to calculate a team's entropy- i.e. their unpredictability.\n",
    "    \n",
    "    n = net\n",
    "    n = nx.relabel_nodes(n, {0:10000000000})\n",
    "    \n",
    "    # A stochastic graph gives the probabilities of connections between certain platers       \n",
    "    prob = nx.stochastic_graph(n)\n",
    "    \n",
    "    # Allows us to sort nodes alphabetically so that we can easily remove shot node later\n",
    "    nodelist = sorted(list(n.nodes()))\n",
    "    \n",
    "    # Generates transition matrix\n",
    "    probmat = nx.adjacency_matrix(prob, nodelist = nodelist)\n",
    "    probmat = probmat.todense()\n",
    "    matrix = np.array(probmat) # turns it into numpy array so that we can operate on it\n",
    "\n",
    "    #entnode =  np.apply_along_axis( entropy, axis=1, arr = matrix ) # calculates entropy for each node\n",
    "    \n",
    "    entnode = []\n",
    "    for row in matrix:\n",
    "        e = 0\n",
    "        for item in row:\n",
    "            if item >0:\n",
    "                e -= item * math.log10(item)\n",
    "        entnode.append(e)\n",
    "    \n",
    "    entnode = entnode[:-1] # Gets rid of entropy of shot node\n",
    "    \n",
    "#     matchid = []\n",
    "#     teamid = []\n",
    "#     for i in range(len(entnode)):\n",
    "#         matchid.append(match)\n",
    "#         teamid.append(team)\n",
    "\n",
    "#     entrop = sum(entnode)/len(n.nodes()) # Gets the average\n",
    "        \n",
    "    return entnode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betweenness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#betweenness\n",
    "def find_betweenness(net,playerlist):\n",
    "    \n",
    "    n = net\n",
    "\n",
    "    dic = nx.betweenness_centrality(n, normalized = False, weight = 'weight') #Just uses nx built ins. # weight?\n",
    "    \n",
    "    met = []\n",
    "    for player in playerlist:\n",
    "        met.append(dic[player])\n",
    "    \n",
    "#     playerlist = list(bet.keys())\n",
    "#     betweenness = list(bet.values())\n",
    "    \n",
    "#     matchid = []\n",
    "#     teamid = []\n",
    "#     for i in range(len(playerlist)):\n",
    "#         matchid.append(match)\n",
    "#         teamid.append(team)\n",
    "    \n",
    "    return met"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Closeness "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closeness(net,playerlist):\n",
    "    \n",
    "    n = net\n",
    "\n",
    "    out_close = nx.algorithms.centrality.closeness_centrality(n.reverse())\n",
    "    in_close  = nx.algorithms.centrality.closeness_centrality(n)\n",
    "    \n",
    "    met = []\n",
    "    for player in playerlist:\n",
    "        met.append((out_close[player]+in_close[player])/2)\n",
    "    \n",
    "#     co = list(out_close.values())\n",
    "#     ci = list(in_close.values())\n",
    "#     summ = [(co[i] + ci[i])/2 for i in range(len(co))]\n",
    "#     close = {}\n",
    "#     keys = list(out_close.keys())\n",
    "#     for i in range(len( summ ) ):\n",
    "#         close[keys[i]] = summ[i]\n",
    "        \n",
    "#     playerlist = list(close.keys())\n",
    "#     closeness = list(close.values())\n",
    "    \n",
    "#     matchid = []\n",
    "#     teamid = []\n",
    "#     for i in range(len(playerlist)):\n",
    "#         matchid.append(match)\n",
    "#         teamid.append(team)\n",
    "    \n",
    "    # The closeness centrality uses inward distance to a node, not outward. If you want to use outward \n",
    "    # distances apply the function to G.reverse(). We want both, with equal weighting, so we add them up.\n",
    "    #close =  np.mean( sum(list( out_close.values() ))/11 + sum(list(in_close.values()))/11 )\n",
    "    \n",
    "    return met"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clustering(net, playerlist):\n",
    "    n = net\n",
    "    \n",
    "    dic = nx.clustering(n)\n",
    "    #clus = sum( list(dict(cluplayers).values())) /11\n",
    "    # clus = nx.algorithms.transitivity(n)\n",
    "    # Transitivity and clustering are similarly defined but slightly different. Transitivity gives more \n",
    "    # weight to higher degree nodes, and clustering gives more weight to lower degree nodes.\n",
    "    \n",
    "    met = []\n",
    "    for player in playerlist:\n",
    "        met.append(dic[player])\n",
    "    \n",
    "#     playerlist = list(cluplayers.keys())\n",
    "#     clustering = list(cluplayers.values())\n",
    "    \n",
    "#     matchid = []\n",
    "#     teamid = []\n",
    "#     for i in range(len(playerlist)):\n",
    "#         matchid.append(match)\n",
    "#         teamid.append(team)\n",
    "    \n",
    "    \n",
    "    return met"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eVector centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_evec(net, playerlist):\n",
    "    \n",
    "    n = net\n",
    "    \n",
    "    # Gets list of every player's eigenvector centrality and takes the standard deviation of that list.\n",
    "    dic = nx.algorithms.centrality.eigenvector_centrality(n,max_iter = 10000)\n",
    "    \n",
    "    evec_cent = []\n",
    "    for player in playerlist:\n",
    "        evec_cent.append(dic[player])\n",
    "    \n",
    "#     playerlist = list(evec.keys())\n",
    "#     #evecstd = np.std(evec)\n",
    "#     evec_cent = list(evec.values())\n",
    "    \n",
    "#     matchid = []\n",
    "#     teamid = []\n",
    "#     for i in range(len(playerlist)):\n",
    "#         matchid.append(match)\n",
    "#         teamid.append(team)\n",
    "    \n",
    "    return evec_cent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outdegree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out degree\n",
    "def find_outdeg(net,playerlist):\n",
    "    n = net\n",
    "    # Gives dictionaries of the metrics for each node.\n",
    "    dic = dict ( n.out_degree() )\n",
    "    \n",
    "    degree = []\n",
    "    for player in playerlist:\n",
    "        degree.append(dic[player])\n",
    "    \n",
    "    return degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_calc(net,metric, playerlist):\n",
    "    \n",
    "    if metric == 'passes':\n",
    "        met = 0\n",
    "        for item in list(net.edges(data=True)):\n",
    "            met += item[2]['weight']\n",
    "    elif metric == 'entropy':\n",
    "        met = find_entropy(net, playerlist)\n",
    "    elif metric == 'outdegree':\n",
    "        met = find_outdeg(net, playerlist)\n",
    "    elif metric == 'indegree':\n",
    "        met = find_indeg(net)\n",
    "    elif metric == 'outstrength':\n",
    "        met = find_outstr(net)\n",
    "    elif metric == 'instrength':\n",
    "        met = find_instr(net)\n",
    "    elif metric == 'betweenness':\n",
    "        met = find_betweenness(net, playerlist)\n",
    "    elif metric == 'nonzero_betweenness':\n",
    "        met = find_nonzero(net)\n",
    "    elif metric == 'closeness':\n",
    "        met = find_closeness(net, playerlist)\n",
    "    elif metric == 'clustering':\n",
    "        met = find_clustering(net, playerlist)\n",
    "    elif metric == 'eigenvector':\n",
    "        met = find_evec(net, playerlist)\n",
    "\n",
    "    return met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_window(df,time,teams, metric, match):\n",
    "    # This function iterates sliding 10 minute windows, moving forward by 30 seconds each time and calculate a \n",
    "    # team's entropy during that 30 second window\n",
    "\n",
    "    metrics1 = []\n",
    "    metrics2 = []\n",
    "\n",
    "    # locate the window in the database\n",
    "    temp_df = df.loc[df['eventSec'] < time]\n",
    "    #temp_df = temp_df.loc[temp_df['eventSec'] > time-600]\n",
    "\n",
    "    # Get pass list, create a network, and find that network's entropy\n",
    "    pass1, pass2 = passeslist(temp_df, teams)\n",
    "\n",
    "    net1 = weighted_passes(pass1)\n",
    "    net2 = weighted_passes(pass2)\n",
    "\n",
    "    # The team's total amount of passes during that 10 minute window \n",
    "    tot1 = 0\n",
    "    tot2 = 0\n",
    "    for item in list(net1.edges(data=True)):\n",
    "        tot1 += item[2]['weight']\n",
    "    for item in list(net2.edges(data=True)):\n",
    "        tot2 += item[2]['weight']\n",
    "\n",
    "    metric_names = ['entropy','outdegree','betweenness','closeness','clustering','eigenvector']\n",
    "    \n",
    "    playerlist1 = sorted(list(net1.nodes()))\n",
    "    playerlist2 = sorted(list(net2.nodes()))\n",
    "\n",
    "    if 0 in playerlist1:\n",
    "        playerlist1 = playerlist1[1:]\n",
    "\n",
    "    if 0 in playerlist2:\n",
    "        playerlist2 = playerlist2[1:]\n",
    "\n",
    "    matchid = []\n",
    "    for i in range(len(playerlist1)+len(playerlist2)):\n",
    "        matchid.append(match)\n",
    "\n",
    "    teamid = []\n",
    "    for i in range(len(playerlist1)):\n",
    "        teamid.append(teams[0])\n",
    "    for i in range(len(playerlist2)):\n",
    "        teamid.append(teams[1])\n",
    "    \n",
    "    mets = []\n",
    "    for metric in metric_names:\n",
    "        \n",
    "        if tot1 > 0:\n",
    "            met1 = metric_calc(net1, metric, playerlist1)\n",
    "        else:\n",
    "            met1 = 0\n",
    "        if tot2 > 0:\n",
    "            met2 = metric_calc(net2, metric, playerlist2)\n",
    "        else:\n",
    "            met2 = 0\n",
    "            \n",
    "        mets.append(met1 + met2)\n",
    "    \n",
    "    players = playerlist1 + playerlist2\n",
    "    \n",
    "    results = list(zip(matchid,teamid,players,mets[0],mets[1],mets[2],mets[3],mets[4],mets[5]))\n",
    "    \n",
    "    metric_df = pd.DataFrame(results, columns = ['matchId','teamId','playerId','entropy','outdegree','betweenness',\n",
    "                                                 'closeness','clustering','eigenvector'])\n",
    "    \n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_iterator(master_df,league, metric,time):\n",
    "    \n",
    "    #Shows what the longest half is and converts to longest possible match\n",
    "    #longest_game = math.ceil(max(master_df['eventSec'])*2 / 60)\n",
    "    \n",
    "    matches = list(set(master_df['matchId']))\n",
    "    \n",
    "    mins = []\n",
    "    for i in range(10,170):\n",
    "        mins.append(i/2)\n",
    "        \n",
    "    results = []\n",
    "    \n",
    "    metric_df = pd.DataFrame()\n",
    "    for m in range(len(matches)):\n",
    "\n",
    "        #print(m)\n",
    "        match = matches[m]\n",
    "\n",
    "        df = get_game(master_df,match)\n",
    "        df = continuous_time(df)\n",
    "        df = event_handling(df)\n",
    "\n",
    "        teams = list(set(df['teamId']))\n",
    "        \n",
    "        metric_df = pd.concat([metric_df, time_window(df,time, teams, metric, match)],ignore_index = True )\n",
    "\n",
    "#         met1, met2 = time_window(df,time, teams, metric, match)\n",
    "        \n",
    "#         for item in met1:\n",
    "#             results.append(item)\n",
    "#         for item in met2:\n",
    "#             results.append(item)\n",
    "    \n",
    "#     metric_df = pd.DataFrame(results, columns = ['matchId','teamId','playerId','outdegree'])\n",
    "    \n",
    "    return metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in teams df\n",
    "Teams = pd.read_json('teams.json')\n",
    "Teams = Teams.rename(columns = {'wyId': 'teamId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(cleaned_events):\n",
    "    \n",
    "    #metric_names = ['passes','entropy','outdegree','indegree','outstrength','instrength','betweenness',\n",
    "    #             'nonzero_betweenness','closeness','clustering','eigenvector_std']\n",
    "    metric='outdegree'\n",
    "    \n",
    "    times = []\n",
    "    for time in range(600, 6000, 600):\n",
    "        times.append(time)\n",
    "    \n",
    "    #for metric in metric_names:\n",
    "    for t in times:\n",
    "        print(t/60)\n",
    "        \n",
    "        live_df = pd.DataFrame()\n",
    "        for name in cleaned_events:\n",
    "            df = initial_df_processing(name)\n",
    "        \n",
    "            met_df = game_iterator(df, name, metric, t)\n",
    "            \n",
    "            live_df = pd.concat([live_df,met_df],ignore_index = True)\n",
    "        \n",
    "        live_df.to_json('MetAggs/met_live_'+str(int(t/60)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cleaned_events_England.json',\n",
       " 'cleaned_events_France.json',\n",
       " 'cleaned_events_Spain.json',\n",
       " 'cleaned_events_European_Championship.json',\n",
       " 'cleaned_events_World_Cup.json',\n",
       " 'cleaned_events_Germany.json',\n",
       " 'cleaned_events_Italy.json']"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py:1773: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n",
      "30.0\n",
      "40.0\n",
      "50.0\n",
      "60.0\n",
      "70.0\n",
      "80.0\n",
      "90.0\n"
     ]
    }
   ],
   "source": [
    "main(cleaned_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio  controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"https://sound.peal.io/ps/audios/000/000/537/original/woo_vu_luvub_dub_dub.wav\" type=\"audio/x-wav\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "allDone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('MetAggs/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg = pd.read_json('/Users/Yuval/Desktop/Pawsey/data/ClusteringAggs/clustering_live_90')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matchId</th>\n",
       "      <th>teamId</th>\n",
       "      <th>playerId</th>\n",
       "      <th>clustering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2499719</td>\n",
       "      <td>1609</td>\n",
       "      <td>25413</td>\n",
       "      <td>0.732759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2499719</td>\n",
       "      <td>1609</td>\n",
       "      <td>370224</td>\n",
       "      <td>0.783951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2499719</td>\n",
       "      <td>1609</td>\n",
       "      <td>3319</td>\n",
       "      <td>0.743781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2499719</td>\n",
       "      <td>1609</td>\n",
       "      <td>120339</td>\n",
       "      <td>0.779006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2499719</td>\n",
       "      <td>1609</td>\n",
       "      <td>167145</td>\n",
       "      <td>0.731707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56198</th>\n",
       "      <td>2576338</td>\n",
       "      <td>3185</td>\n",
       "      <td>21234</td>\n",
       "      <td>0.515337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56199</th>\n",
       "      <td>2576338</td>\n",
       "      <td>3185</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56200</th>\n",
       "      <td>2576338</td>\n",
       "      <td>3185</td>\n",
       "      <td>354552</td>\n",
       "      <td>0.297619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56201</th>\n",
       "      <td>2576338</td>\n",
       "      <td>3185</td>\n",
       "      <td>14745</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56202</th>\n",
       "      <td>2576338</td>\n",
       "      <td>3185</td>\n",
       "      <td>20812</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56203 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       matchId  teamId  playerId  clustering\n",
       "0      2499719    1609     25413    0.732759\n",
       "1      2499719    1609    370224    0.783951\n",
       "2      2499719    1609      3319    0.743781\n",
       "3      2499719    1609    120339    0.779006\n",
       "4      2499719    1609    167145    0.731707\n",
       "...        ...     ...       ...         ...\n",
       "56198  2576338    3185     21234    0.515337\n",
       "56199  2576338    3185         0    1.000000\n",
       "56200  2576338    3185    354552    0.297619\n",
       "56201  2576338    3185     14745    0.200000\n",
       "56202  2576338    3185     20812    0.500000\n",
       "\n",
       "[56203 rows x 4 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I forgot to remove shot node!\n",
    "def remove_shot_node(df):\n",
    "    df = df.loc[df['playerId']!=0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir('EigenvectorAggs/'):\n",
    "    df = pd.read_json('EigenvectorAggs/'+file)\n",
    "    df = remove_shot_node(df)\n",
    "    df.to_json('EigenvectorAggs/'+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ys/xd1k0y7j01xghctdv8ktdd900000gn/T/ipykernel_16584/121810302.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnet1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_passes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpass1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mnet2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_passes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpass2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmet1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mmet2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_calc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/ys/xd1k0y7j01xghctdv8ktdd900000gn/T/ipykernel_16584/196982734.py\u001b[0m in \u001b[0;36mmetric_calc\u001b[0;34m(net, metric)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mmet\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'entropy'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'outdegree'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mmet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_outdeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/ys/xd1k0y7j01xghctdv8ktdd900000gn/T/ipykernel_16584/2365143567.py\u001b[0m in \u001b[0;36mfind_entropy\u001b[0;34m(net)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Allows us to sort nodes alphabetically so that we can easily remove shot node later\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mplayerlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Generates transition matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'str'"
     ]
    }
   ],
   "source": [
    "name = 'cleaned_events_Italy.json'\n",
    "df = initial_df_processing(name)\n",
    "matches = list(set(df['matchId']))\n",
    "metric = 'entropy'\n",
    "match = matches[0]\n",
    "df = get_game(df,match)\n",
    "df = continuous_time(df)\n",
    "df = event_handling(df)\n",
    "teams = list(set(df['teamId']))\n",
    "pass1, pass2 = passeslist(df, teams)\n",
    "net1 = weighted_passes(pass1)\n",
    "net2 = weighted_passes(pass2)\n",
    "met1 = metric_calc(net1, metric)\n",
    "met2 = metric_calc(net2, metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
